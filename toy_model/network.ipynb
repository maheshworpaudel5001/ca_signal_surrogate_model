{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/gddaslab/mxp140/ca_signaling_surrogate_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "import pickle\n",
    "from models import GRUModel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# ----------------------------\n",
    "#        DEVICE SETUP\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Enable cuDNN autotuner for faster performance on fixed input sizes\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "#       DATA LOADING\n",
    "# ----------------------------\n",
    "NUM_FEATURES = 1\n",
    "NUM_TRAJECTORIES = 100\n",
    "NUM_T_INPUTS = 50\n",
    "all_input = NUM_TRAJECTORIES\n",
    "input_arr = np.load(\"improper_solutions.npy\")\n",
    "output_arr = np.loadtxt(\"improper_k_samples.txt\").reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "#       NORMALIZATION\n",
    "# ----------------------------\n",
    "# Reshape input: (N, T, F) â†’ (N*T, F)\n",
    "input_2d = input_arr.reshape(-1, NUM_FEATURES)\n",
    "input_scaler = MinMaxScaler()\n",
    "input_scaled = input_scaler.fit_transform(input_2d)\n",
    "norm_in_arr = input_scaled.reshape(input_arr.shape)\n",
    "# Output: shape (N, 5)\n",
    "output_scaler = MinMaxScaler()\n",
    "norm_out_arr = output_scaler.fit_transform(output_arr)\n",
    "# Save scalers for use during prediction\n",
    "with open(\"improper_input_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(input_scaler, f)\n",
    "with open(\"improper_output_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(output_scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "#       DATASET PREP\n",
    "# ----------------------------\n",
    "input_tensor = torch.from_numpy(norm_in_arr).float()  # (N, T, F)\n",
    "output_tensor = torch.from_numpy(norm_out_arr).float()  # (N, 1)\n",
    "\n",
    "# Create a single dataset with three outputs\n",
    "dataset = TensorDataset(input_tensor, output_tensor)\n",
    "\n",
    "# Train/Val Split\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.9 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "#       MODEL SETUP\n",
    "# ----------------------------\n",
    "input_dim = NUM_FEATURES\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "num_layers = 1  # number of GRU layers\n",
    "dropout = (\n",
    "    0.1 if num_layers > 1 else 0.0\n",
    ")  # dropout probability is the same for all layers regressors\n",
    "bidirectional = False\n",
    "\n",
    "model = GRUModel(\n",
    "    input_dim, hidden_dim, output_dim, num_layers, bidirectional, dropout\n",
    ").to(device)\n",
    "# Optional: Compile model (requires PyTorch 2.0+)\n",
    "model = torch.compile(model)\n",
    "\n",
    "# We will have a combined loss for trajectory and parameter\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "scaler = GradScaler(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.5165, Validation Loss: 0.3266 -- Model saved\n",
      "Epoch [2/100], Train Loss: 0.4739, Validation Loss: 0.2932 -- Model saved\n",
      "Epoch [3/100], Train Loss: 0.4339, Validation Loss: 0.2625 -- Model saved\n",
      "Epoch [4/100], Train Loss: 0.3961, Validation Loss: 0.2339 -- Model saved\n",
      "Epoch [5/100], Train Loss: 0.3613, Validation Loss: 0.2064 -- Model saved\n",
      "Epoch [6/100], Train Loss: 0.3251, Validation Loss: 0.1804 -- Model saved\n",
      "Epoch [7/100], Train Loss: 0.2911, Validation Loss: 0.1547 -- Model saved\n",
      "Epoch [8/100], Train Loss: 0.2566, Validation Loss: 0.1294 -- Model saved\n",
      "Epoch [9/100], Train Loss: 0.2199, Validation Loss: 0.1051 -- Model saved\n",
      "Epoch [10/100], Train Loss: 0.1843, Validation Loss: 0.0818 -- Model saved\n",
      "Epoch [11/100], Train Loss: 0.1471, Validation Loss: 0.0626 -- Model saved\n",
      "Epoch [12/100], Train Loss: 0.1095, Validation Loss: 0.0530 -- Model saved\n",
      "Epoch [13/100], Train Loss: 0.088471, Validation Loss: 0.060854\n",
      "Epoch [14/100], Train Loss: 0.079038, Validation Loss: 0.080039\n",
      "Epoch [15/100], Train Loss: 0.080856, Validation Loss: 0.076206\n",
      "Epoch [16/100], Train Loss: 0.077258, Validation Loss: 0.063541\n",
      "Epoch [17/100], Train Loss: 0.076975, Validation Loss: 0.061979\n",
      "Epoch [18/100], Train Loss: 0.076838, Validation Loss: 0.064615\n",
      "Epoch [19/100], Train Loss: 0.076328, Validation Loss: 0.065555\n",
      "Epoch [20/100], Train Loss: 0.076565, Validation Loss: 0.066166\n",
      "Epoch [21/100], Train Loss: 0.076132, Validation Loss: 0.063514\n",
      "Epoch [22/100], Train Loss: 0.075397, Validation Loss: 0.065358\n",
      "Epoch [23/100], Train Loss: 0.075174, Validation Loss: 0.066776\n",
      "Epoch [24/100], Train Loss: 0.075067, Validation Loss: 0.066549\n",
      "Epoch [25/100], Train Loss: 0.074694, Validation Loss: 0.063785\n",
      "Epoch [26/100], Train Loss: 0.074802, Validation Loss: 0.065679\n",
      "Epoch [27/100], Train Loss: 0.074185, Validation Loss: 0.064351\n",
      "Epoch [28/100], Train Loss: 0.073952, Validation Loss: 0.062337\n",
      "Epoch [29/100], Train Loss: 0.073819, Validation Loss: 0.063425\n",
      "Epoch [30/100], Train Loss: 0.073585, Validation Loss: 0.063398\n",
      "Epoch [31/100], Train Loss: 0.073052, Validation Loss: 0.063337\n",
      "Epoch [32/100], Train Loss: 0.073183, Validation Loss: 0.066372\n",
      "Epoch [33/100], Train Loss: 0.072509, Validation Loss: 0.062669\n",
      "Epoch [34/100], Train Loss: 0.072613, Validation Loss: 0.062787\n",
      "Epoch [35/100], Train Loss: 0.072204, Validation Loss: 0.063242\n",
      "Epoch [36/100], Train Loss: 0.071604, Validation Loss: 0.061995\n",
      "Epoch [37/100], Train Loss: 0.071409, Validation Loss: 0.061304\n",
      "Epoch [38/100], Train Loss: 0.071547, Validation Loss: 0.064650\n",
      "Epoch [39/100], Train Loss: 0.070857, Validation Loss: 0.062580\n",
      "Epoch [40/100], Train Loss: 0.070604, Validation Loss: 0.059449\n",
      "Epoch [41/100], Train Loss: 0.070250, Validation Loss: 0.061532\n",
      "Epoch [42/100], Train Loss: 0.069831, Validation Loss: 0.061209\n",
      "Epoch [43/100], Train Loss: 0.069512, Validation Loss: 0.061556\n",
      "Epoch [44/100], Train Loss: 0.069247, Validation Loss: 0.059925\n",
      "Epoch [45/100], Train Loss: 0.068927, Validation Loss: 0.062579\n",
      "Epoch [46/100], Train Loss: 0.068287, Validation Loss: 0.061038\n",
      "Epoch [47/100], Train Loss: 0.068062, Validation Loss: 0.057199\n",
      "Epoch [48/100], Train Loss: 0.068336, Validation Loss: 0.057073\n",
      "Epoch [49/100], Train Loss: 0.067898, Validation Loss: 0.064624\n",
      "Epoch [50/100], Train Loss: 0.066907, Validation Loss: 0.060160\n",
      "Epoch [51/100], Train Loss: 0.066901, Validation Loss: 0.058494\n",
      "Epoch [52/100], Train Loss: 0.0667, Validation Loss: 0.0528 -- Model saved\n",
      "Epoch [53/100], Train Loss: 0.065389, Validation Loss: 0.056603\n",
      "Epoch [54/100], Train Loss: 0.064746, Validation Loss: 0.057246\n",
      "Epoch [55/100], Train Loss: 0.064089, Validation Loss: 0.060952\n",
      "Epoch [56/100], Train Loss: 0.064735, Validation Loss: 0.053855\n",
      "Epoch [57/100], Train Loss: 0.062513, Validation Loss: 0.056613\n",
      "Epoch [58/100], Train Loss: 0.062091, Validation Loss: 0.060815\n",
      "Epoch [59/100], Train Loss: 0.0617, Validation Loss: 0.0527 -- Model saved\n",
      "Epoch [60/100], Train Loss: 0.060692, Validation Loss: 0.057183\n",
      "Epoch [61/100], Train Loss: 0.059134, Validation Loss: 0.052709\n",
      "Epoch [62/100], Train Loss: 0.0580, Validation Loss: 0.0514 -- Model saved\n",
      "Epoch [63/100], Train Loss: 0.056935, Validation Loss: 0.054006\n",
      "Epoch [64/100], Train Loss: 0.0550, Validation Loss: 0.0495 -- Model saved\n",
      "Epoch [65/100], Train Loss: 0.0532, Validation Loss: 0.0492 -- Model saved\n",
      "Epoch [66/100], Train Loss: 0.0511, Validation Loss: 0.0489 -- Model saved\n",
      "Epoch [67/100], Train Loss: 0.0483, Validation Loss: 0.0444 -- Model saved\n",
      "Epoch [68/100], Train Loss: 0.0444, Validation Loss: 0.0392 -- Model saved\n",
      "Epoch [69/100], Train Loss: 0.0410, Validation Loss: 0.0363 -- Model saved\n",
      "Epoch [70/100], Train Loss: 0.0338, Validation Loss: 0.0338 -- Model saved\n",
      "Epoch [71/100], Train Loss: 0.0277, Validation Loss: 0.0276 -- Model saved\n",
      "Epoch [72/100], Train Loss: 0.0188, Validation Loss: 0.0198 -- Model saved\n",
      "Epoch [73/100], Train Loss: 0.0107, Validation Loss: 0.0085 -- Model saved\n",
      "Epoch [74/100], Train Loss: 0.0050, Validation Loss: 0.0044 -- Model saved\n",
      "Epoch [75/100], Train Loss: 0.0033, Validation Loss: 0.0027 -- Model saved\n",
      "Epoch [76/100], Train Loss: 0.0021, Validation Loss: 0.0017 -- Model saved\n",
      "Epoch [77/100], Train Loss: 0.004420, Validation Loss: 0.002796\n",
      "Epoch [78/100], Train Loss: 0.0063, Validation Loss: 0.0016 -- Model saved\n",
      "Epoch [79/100], Train Loss: 0.004631, Validation Loss: 0.001951\n",
      "Epoch [80/100], Train Loss: 0.003215, Validation Loss: 0.002360\n",
      "Epoch [81/100], Train Loss: 0.002145, Validation Loss: 0.002360\n",
      "Epoch [82/100], Train Loss: 0.002275, Validation Loss: 0.002247\n",
      "Epoch [83/100], Train Loss: 0.002399, Validation Loss: 0.001805\n",
      "Epoch [84/100], Train Loss: 0.002338, Validation Loss: 0.001786\n",
      "Epoch [85/100], Train Loss: 0.002577, Validation Loss: 0.001677\n",
      "Epoch [86/100], Train Loss: 0.001716, Validation Loss: 0.001964\n",
      "Epoch [87/100], Train Loss: 0.0017, Validation Loss: 0.0016 -- Model saved\n",
      "Epoch [88/100], Train Loss: 0.0017, Validation Loss: 0.0015 -- Model saved\n",
      "Epoch [89/100], Train Loss: 0.001840, Validation Loss: 0.001520\n",
      "Epoch [90/100], Train Loss: 0.0016, Validation Loss: 0.0015 -- Model saved\n",
      "Epoch [91/100], Train Loss: 0.0016, Validation Loss: 0.0014 -- Model saved\n",
      "Epoch [92/100], Train Loss: 0.001690, Validation Loss: 0.001671\n",
      "Epoch [93/100], Train Loss: 0.001743, Validation Loss: 0.001462\n",
      "Epoch [94/100], Train Loss: 0.001839, Validation Loss: 0.002443\n",
      "Epoch [95/100], Train Loss: 0.002524, Validation Loss: 0.003395\n",
      "Epoch [96/100], Train Loss: 0.002725, Validation Loss: 0.003155\n",
      "Epoch [97/100], Train Loss: 0.0018, Validation Loss: 0.0013 -- Model saved\n",
      "Epoch [98/100], Train Loss: 0.0018, Validation Loss: 0.0012 -- Model saved\n",
      "Epoch [99/100], Train Loss: 0.001482, Validation Loss: 0.001355\n",
      "Epoch [100/100], Train Loss: 0.0025, Validation Loss: 0.0011 -- Model saved\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "#      TRAINING LOOP\n",
    "# ----------------------------\n",
    "num_epochs = 100\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X = batch_X.unsqueeze(-1).to(device)  # Adds a dimension at the end â†’ shape becomes [batch_size, 50, 1]\n",
    "        batch_y = batch_y.to(device) #Shape [batch_size, 1]\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            # Forward pass\n",
    "            pred_output = model(batch_X)\n",
    "\n",
    "            # Calculate combined loss\n",
    "            loss = criterion(pred_output, batch_y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    train_loss = running_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_y in val_loader:\n",
    "            val_X = val_X.unsqueeze(-1).to(device)  # Adds a dimension at the end â†’ shape becomes [batch_size, 50, 1]\n",
    "            val_y = val_y.to(device)\n",
    "\n",
    "            with autocast(device_type=\"cuda\"):\n",
    "\n",
    "                pred_output_val = model(val_X)\n",
    "                val_loss = criterion(pred_output_val, val_y)\n",
    "                running_val_loss += val_loss.item()\n",
    "\n",
    "    val_loss = running_val_loss / len(val_loader)\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"toy_model_improper.pth\")\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f} -- Model saved\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "            f\"Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca_signal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
